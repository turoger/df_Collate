{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as ddf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "def big_ddf (directory_to_traits_table,\n",
    "             directory_to_phenotypes, phenotype_list, filename_type,\n",
    "             directory_to_MAF,\n",
    "             gene_name, directory_to_rsid):\n",
    "    '''\n",
    "    Returns a big dask df with: 'SNP', 'ALLELE', 'iScore', 'BETA', 'PV', 'MAF', 'Gene' as headers\n",
    "    '''\n",
    "    \n",
    "    trait_dict = ukbbTT_to_dict(directory_to_traits_table)\n",
    "    pheno_dict = reader(directory_to_phenotypes, phenotype_list, filename_type, trait_dict)\n",
    "    a_ddf = ddf_collapser(pheno_dict)\n",
    "    a_ddf = ddf_MAF_Add(directory_to_MAF, a_ddf)\n",
    "    a_ddf = ddf_Gene_Add(a_ddf, gene_name, directory_to_rsid)\n",
    "    a_ddf = a_ddf.drop(columns = ['NSE'])\n",
    "    \n",
    "    return(a_ddf)\n",
    "\n",
    "\n",
    "#\n",
    "def ukbbTT_to_dict (file_path):\n",
    "    '''\n",
    "    Takes a UKBB trait table file path, maps key's to Descriptions and returns a dictionary mapping\n",
    "    '''\n",
    "    \n",
    "    traits_tb = pd.read_csv(file_path, sep = ',')                                          # read in path of file\n",
    "    \n",
    "    key = traits_tb['key'].tolist()\n",
    "    val = traits_tb['Description'].tolist()\n",
    "    key_des_dict = {key[i]:val[i] for i in range(len(key))}                                # creates dictionary\n",
    "    \n",
    "    key_des_dict.update({'21001-0.0':'BMI (kg/m2)',\n",
    "                        '23104-0.0':'BMI Impedence (kg/m2)',\n",
    "                        '21002-0.0':'Weight(kg)',\n",
    "                        '23098-0.0':'Weight Impedence(kg)'})                               # update dict vals with correct descriptors\n",
    "    return(key_des_dict)\n",
    " \n",
    "    \n",
    "#    \n",
    "def reader (directory, phenoID_list, filename, trait_dict):\n",
    "    '''\n",
    "    Takes a directory of phenotype folders and iterates through the folder's ID in phenoID_list.  \n",
    "    Inside each folder are potentially four different filename: `imputed.all`, `imputed.norm`, `geno.all`, and `geno.norm`.\n",
    "    \n",
    "    Parameters: \n",
    "    directory: the path that holds all the phenotype folders\n",
    "    phenoID_list: list of phenotype Id's you're interested in collating into a dataframe\n",
    "    filename: which subset of imputed/genotyped and non-norm/normed files you want to collate\n",
    "    trait_dict: a dictionary of ID's to Phenotype name mappings\n",
    "    \n",
    "    returns a dictionary based w/ phenoID_list as the key, and the imported dataframe as the value.\n",
    "    '''\n",
    "    \n",
    "    pheno_ddf_ls = dict()\n",
    "    os.chdir(directory)\n",
    "    \n",
    "    for i in phenoID_list:\n",
    "        os.chdir(i)\n",
    "        \n",
    "        for fn in os.listdir():\n",
    "            if fn.startswith(filename):\n",
    "                val = ddf.read_csv(fn, sep = ' ',\n",
    "                                  header = 0,                                               # Ignore initial Headers\n",
    "                                  names = ['SNP', 'ALLELE', 'iScore', 'BETA', 'NSE', 'PV'], # Specifies Headers\n",
    "                                  dtype = {'SNP': object,\n",
    "                                          'ALLELE': object,\n",
    "                                          'iScore': np.float32,\n",
    "                                          'BETA': np.float32,\n",
    "                                          'NSE': np.float32,\n",
    "                                          'PV': np.float32})                                # Change variable type to save memory\n",
    "                val['Phenotype'] = trait_dict[i]                                            # Creates new col with name of df as val\n",
    "                pheno_ddf_ls.update({i:val})\n",
    "        \n",
    "        os.chdir('..')\n",
    "    \n",
    "    return(pheno_ddf_ls)\n",
    "\n",
    "\n",
    "#\n",
    "def ddf_collapser(dict_df):\n",
    "    '''\n",
    "    Takes dict of ddf and collapses dict into a large ddf. Returns a big dask df\n",
    "    '''\n",
    "    \n",
    "    frames = []\n",
    "    for df_name in dict_df.keys():\n",
    "        frames.append(dict_df[df_name]) #add each df to a list\n",
    "    \n",
    "    return(ddf.concat(frames))\n",
    "\n",
    "\n",
    "#\n",
    "def ddf_MAF_Add(file_path, a_ddf):\n",
    "    '''\n",
    "    Takes a UKBB MAF txt file for the specified chromosome and cerates a SNP to MAF dict mapping\n",
    "    Takes a dask df. Creates a new column, MAF, based on k:v pair in snp_dict for ddf in dict\n",
    "    '''\n",
    "    \n",
    "    mfi_header = ['Loc','SNP', 'Position', 'Allele1', 'Allele2', 'MAF', 'MA', 'Info_score']  # Assigns header to csv\n",
    "    mfi = pd.read_csv(file_path, names = mfi_header, sep = \"\\t\")                             # Reads tab sep file with names from mfi_header\n",
    "    \n",
    "    key = mfi['SNP'].tolist()\n",
    "    val = mfi['MAF'].tolist()\n",
    "    snp_maf_dict = {key[i]:val[i] for i in range(len(key))}                                  # Creates dict mapping for Variant and MAF vals \n",
    "\n",
    "    \n",
    "    a_ddf['MAF'] = a_ddf['SNP'].map(snp_maf_dict)                                            # Creates new col with MAF mapped to SNP\n",
    "    a_ddf = (a_ddf\n",
    "             .assign(MAF = lambda df: df['MAF'].astype(np.float32))                          # Changes df data type for 'MAF'\n",
    "            )\n",
    "    return(a_ddf)\n",
    "    \n",
    "    \n",
    "#    \n",
    "def ddf_Gene_Add(a_ddf, gene, rsid_file_path):\n",
    "    ''' \n",
    "    Takes a dask df and sorts by the SNV found in rsid_file_path\n",
    "    \n",
    "    gene: Should be a string to name the values of ddf if the rsid lies within the gene\n",
    "    rsid_file_path: Should be a directory to a text file with all the variants within a gene\n",
    "    \n",
    "    returns a dask df with in `Gene` or `not Gene`\n",
    "    '''\n",
    "    \n",
    "    gene_rsid = open(rsid_file_path, 'r')                                                     # read in text file\n",
    "    gene_rsid_ls = gene_rsid.readlines()                                                      # Add each line as index to a list\n",
    "    \n",
    "    gene_rsid_ls2 = []                                                                        # Strip newline escape, append to list\n",
    "    for index in range(1, len(gene_rsid_ls)):\n",
    "        rsid = gene_rsid_ls[index]\n",
    "        gene_rsid_ls2.append(rsid.rstrip('\\n'))\n",
    "        \n",
    "    a_ddf['Gene'] = a_ddf['SNP'].isin(gene_rsid_ls2)                                          # creates a col of T/F depending if in gene_rsid_ls2\n",
    "    booleanDict = {True: gene, False: 'not_' + gene}                                          # create a dict mapping T/F to a name\n",
    "    a_ddf['Gene'] = a_ddf['Gene'].map(booleanDict)                                            # change col vals based on mapping\n",
    "    \n",
    "    return(a_ddf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
